{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/logo.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\" width=\"128\"/>\n",
    "<img align=\"right\" src=\"images/dans.png\" width=\"128\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://annotation.github.io/text-fabric/) for coding in the Dead-Sea Scrolls.\n",
    "\n",
    "Familiarity with the underlying\n",
    "[data model](https://annotation.github.io/text-fabric/tf/about/datamodel.html)\n",
    "is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Python\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python **3.6**.\n",
    "\n",
    "Install it from [python.org](https://www.python.org) or from\n",
    "[Anaconda](https://www.anaconda.com/download).\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip3 install text-fabric\n",
    "```\n",
    "\n",
    "### Jupyter notebook\n",
    "\n",
    "You need [Jupyter](http://jupyter.org).\n",
    "\n",
    "If it is not already installed:\n",
    "\n",
    "```\n",
    "pip3 install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "If you cloned the repository containing this tutorial,\n",
    "first copy its parent directory to somewhere outside your clone of the repo,\n",
    "before computing with this it.\n",
    "\n",
    "If you pull changes from the repository later, it will not conflict with\n",
    "your computations.\n",
    "\n",
    "Where you put your tutorial directory is up to you.\n",
    "It will work from any directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook\n",
    "\n",
    "This tutorial and its sister tutorials are meant to showcase most of things TF can do.\n",
    "\n",
    "But we also have a [cookbook](cookbook) with a set of focused recipes on tricky things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Text-Fabric will fetch the data set for you from github, and check for updates.\n",
    "\n",
    "The data will be stored in the `text-fabric-data` in your home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "The data of the corpus is organized in features.\n",
    "They are *columns* of data.\n",
    "Think of the corpus as a gigantic spreadsheet, where row 1 corresponds to the\n",
    "first sign, row 2 to the second sign, and so on, for all ~ 1.5 M signs,\n",
    "followed by ~ 500 K word nodes and yet another 200 K nodes of other types.\n",
    "\n",
    "The information which reading each sign has, constitutes a column in that spreadsheet.\n",
    "The DSS corpus contains > 50 columns.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:16.202764Z",
     "start_time": "2018-05-18T09:17:16.197546Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incantation\n",
    "\n",
    "The simplest way to get going is by this *incantation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:17.537171Z",
     "start_time": "2018-05-18T09:17:17.517809Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf.app import use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very last version, use `hot`.\n",
    "\n",
    "For the latest release, use `latest`.\n",
    "\n",
    "If you have cloned the repos (TF app and data), use `clone`.\n",
    "\n",
    "If you do not want/need to upgrade, leave out the checkout specifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">TF-app:</b> <span title=\"repo clone offline under ~/github\">~/github/annotation/app-dss/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">data:</b> <span title=\"repo clone offline under ~/github\">~/github/etcbc/dss/tf/0.6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local github\">data:</b> <span title=\"repo clone offline under ~/github\">~/github/etcbc/dss/parallels/tf/0.6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.3.0</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-dss\" title=\"dss TF-app\">app-dss</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs/about.md\" title=\"provenance of Dead Sea Scrolls\">DSS</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"DSS feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Parallel Passages</b></summary><b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/dss/blob/master/programs/parallels.ipynb\" title=\"~/github/etcbc/dss/parallels/tf/0.6/sim.tf\">sim</a></i></b><br></details><details><summary><b>Dead Sea Scrolls</b></summary><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/after.tf\">after</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/alt.tf\">alt</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/biblical.tf\">biblical</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/book.tf\">book</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/cl.tf\">cl</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/cl2.tf\">cl2</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/cor.tf\">cor</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/fragment.tf\">fragment</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/full.tf\">full</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/fulle.tf\">fulle</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/fullo.tf\">fullo</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glex.tf\">glex</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glexe.tf\">glexe</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glexo.tf\">glexo</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glyph.tf\">glyph</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glyphe.tf\">glyphe</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/glypho.tf\">glypho</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/gn2.tf\">gn2</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/gn3.tf\">gn3</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/halfverse.tf\">halfverse</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/intl.tf\">intl</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/lang.tf\">lang</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/lexe.tf\">lexe</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/lexo.tf\">lexo</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/line.tf\">line</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/md.tf\">md</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/merr.tf\">merr</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/morpho.tf\">morpho</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/nu2.tf\">nu2</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/nu3.tf\">nu3</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/ps2.tf\">ps2</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/ps3.tf\">ps3</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/punc.tf\">punc</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/punce.tf\">punce</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/punco.tf\">punco</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/rec.tf\">rec</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/rem.tf\">rem</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/script.tf\">script</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/scroll.tf\">scroll</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/srcLn.tf\">srcLn</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/st.tf\">st</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/type.tf\">type</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/unc.tf\">unc</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/vac.tf\">vac</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/occ.tf\">occ</a></i></b><br><b><i><a target=\"_blank\" href=\"https://github.com/etcbc/dss/blob/master/docs\" title=\"~/github/etcbc/dss/tf/0.6/oslots.tf\">oslots</a></i></b><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 0.1rem;\n",
       "    margin: 0.1rem;\n",
       "    direction: ltr;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1rem 0rem;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".section {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--section);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  0.5rem 0.1rem 0.1rem 0.1rem;\n",
       "    margin: 0.8rem 0.1rem 0.1rem 0.1rem;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 0.2rem;\n",
       "    margin-left: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 0.2rem;\n",
       "    margin-right: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -1.2rem;\n",
       "    margin-left: 1rem;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3rem;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 0.1rem;\n",
       "    margin-left: 0.1rem;\n",
       "    padding: 0.1rem 0.1rem;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 2rem;\n",
       "\tpadding: 1rem;\n",
       "\tborder: 0.1rem solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--section:            hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         0.15rem;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   0.1rem;\n",
       "  --border-width0:      0.1rem;\n",
       "  --border-width1:      0.15rem;\n",
       "  --border-width2:      0.2rem;\n",
       "  --border-width3:      0.3rem;\n",
       "  --border-width4:      0.25rem;\n",
       "  --border-width-plain: 0.1rem;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 0.2rem ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 0.2rem ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.3rem;\n",
       "  padding: 0.2rem;\n",
       "  margin: 0.2rem;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       ".full,.glyph,.punc {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "}\n",
       ".scriptpaleohebrew {\n",
       "    border: 1px dashed navy;\n",
       "}\n",
       ".scriptgreekcapital {\n",
       "    border: 1px dashed brown;\n",
       "}\n",
       ".langa {\n",
       "    text-decoration: underline;\n",
       "}\n",
       ".intl1 {\n",
       "    vertical-align: -0.25em;\n",
       "}\n",
       ".intl2 {\n",
       "    vertical-align: -0.5em;\n",
       "}\n",
       ".langg {\n",
       "    font-family: serif;\n",
       "    text-decoration: underline;\n",
       "}\n",
       ".vac1 {\n",
       "    background-color: #aaaaaa;\n",
       "    border 2pt solid #dd3333;\n",
       "    border-radius: 4pt;\n",
       "}\n",
       ".rem1 {\n",
       "    font-weight: bold;\n",
       "    color: red;\n",
       "    text-decoration: line-through;\n",
       "}\n",
       ".rem2 {\n",
       "    font-weight: bold;\n",
       "    color: maroon;\n",
       "    text-decoration: line-through;\n",
       "}\n",
       ".rec1 {\n",
       "    color: teal;\n",
       "    font-size: 80%;\n",
       "}\n",
       ".cor1 {\n",
       "    font-weight: bold;\n",
       "    color: dodgerblue;\n",
       "    text-decoration: overline;\n",
       "}\n",
       ".cor2 {\n",
       "    font-weight: bold;\n",
       "    color: navy;\n",
       "    text-decoration: overline;\n",
       "}\n",
       ".cor3 {\n",
       "    font-weight: bold;\n",
       "    color: navy;\n",
       "    text-decoration: overline;\n",
       "    vertical-align: super;\n",
       "}\n",
       ".alt1 {\n",
       "    text-decoration: overline;\n",
       "}\n",
       "\n",
       "/* UNSURE: italic*/\n",
       "\n",
       ".unc1 {\n",
       "    font-weight: bold;\n",
       "    color: #888888;\n",
       "}\n",
       ".unc2 {\n",
       "    font-weight: bold;\n",
       "    color: #bbbbbb;\n",
       "}\n",
       ".unc3 {\n",
       "    font-weight: bold;\n",
       "    color: #bbbbbb;\n",
       "    text-shadow: #cccccc 1px 1px;\n",
       "}\n",
       ".unc4 {\n",
       "    font-weight: bold;\n",
       "    color: #dddddd;\n",
       "    text-shadow: #eeeeee 2px 2px;\n",
       "}\n",
       "\n",
       ".empty {\n",
       "  color: #ff0000;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use(\"dss:clone\", checkout=\"clone\", hoist=globals())\n",
    "# A = use('dss:hot', checkout='hot', hoist=globals())\n",
    "# A = use('dss:latest', checkout='latest', hoist=globals())\n",
    "# A = use('dss', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which features have been loaded, and if you click on a feature name, you find its documentation.\n",
    "If you hover over a name, you see where the feature is located on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The result of the incantation is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the corpus.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric API documentation\n",
    "(see the links under **API Members** above).\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute.\n",
    "\n",
    "The **API members** above show you exactly which new names have been inserted in your namespace.\n",
    "If you click on these names, you go to the API documentation for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the data,\n",
    "of this corpus, but also for other corpora and data that you add to corpora.\n",
    "\n",
    "**Search is the quickest way to come up-to-speed with your data, without too much programming.**\n",
    "\n",
    "Jump to the dedicated [search](search.ipynb) search tutorial first, to whet your appetite.\n",
    "\n",
    "The real power of search lies in the fact that it is integrated in a programming environment.\n",
    "You can use programming to:\n",
    "\n",
    "* compose dynamic queries\n",
    "* process query results\n",
    "\n",
    "Therefore, the rest of this tutorial is still important when you want to tap that power.\n",
    "If you continue here, you learn all the basics of data-navigation with Text-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the\n",
    "[`N.walk()` generator](https://annotation.github.io/text-fabric/tf/core/nodes.html#tf.core.nodes.Nodes.walk)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the TF data to a gigantic spreadsheet, where the rows correspond to the signs.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with signs.\n",
    "\n",
    "We also mentioned that there are also other textual objects.\n",
    "They are the clusters, lines, faces and documents.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that\n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:43.894153Z",
     "start_time": "2018-05-18T09:17:43.597128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.27s 2107863 nodes\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"Counting nodes ...\")\n",
    "\n",
    "i = 0\n",
    "for n in N.walk():\n",
    "    i += 1\n",
    "\n",
    "A.info(\"{} nodes\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: over 2M nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "But what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:47.820323Z",
     "start_time": "2018-05-18T09:17:47.812328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:48.549430Z",
     "start_time": "2018-05-18T09:17:48.543371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.251302Z",
     "start_time": "2018-05-18T09:17:49.244467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2107863"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:49.922863Z",
     "start_time": "2018-05-18T09:17:49.916078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('scroll', 'lex', 'fragment', 'line', 'cluster', 'word', 'sign')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:51.782779Z",
     "start_time": "2018-05-18T09:17:51.774167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('scroll', 1428.8121878121879, 1605868, 1606868),\n",
       " ('lex', 129.1396172248804, 1542523, 1552972),\n",
       " ('fragment', 127.90565194061885, 1531341, 1542522),\n",
       " ('line', 27.03924756593251, 1552973, 1605867),\n",
       " ('cluster', 6.678582379647672, 1430242, 1531340),\n",
       " ('word', 2.814359424744758, 1606869, 2107863),\n",
       " ('sign', 1, 1, 1430241))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.levels.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting: above you see all the textual objects, with the average size of their objects,\n",
    "the node where they start, and the node where they end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed\n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:17:57.806821Z",
     "start_time": "2018-05-18T09:17:57.558523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s    1001 scrolls\n",
      "   |     0.00s   10450 lexs\n",
      "   |     0.00s   11182 fragments\n",
      "   |     0.01s   52895 lines\n",
      "   |     0.01s  101099 clusters\n",
      "   |     0.05s  500995 words\n",
      "   |     0.13s 1430241 signs\n",
      "  0.21s Done\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"counting objects ...\")\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    A.indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype):\n",
    "        i += 1\n",
    "\n",
    "    A.info(\"{:>7} {}s\".format(i, otype))\n",
    "\n",
    "A.indent(level=0)\n",
    "A.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing textual objects\n",
    "\n",
    "You can use the A API (the extra power) to display cuneiform text.\n",
    "\n",
    "See the [display](display.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first.\n",
    "Here are the parts of speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ptcl', 154464),\n",
       " ('subs', 108562),\n",
       " ('unknown', 80256),\n",
       " ('verb', 58873),\n",
       " ('suff', 45747),\n",
       " ('adjv', 10633),\n",
       " ('numr', 6526),\n",
       " ('pron', 5784))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sp.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signs, words and clusters have types. We can count them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('rec', 93733),\n",
       " ('vac', 3522),\n",
       " ('cor3', 1582),\n",
       " ('unc2', 906),\n",
       " ('rem2', 706),\n",
       " ('alt', 333),\n",
       " ('cor2', 147),\n",
       " ('cor', 95),\n",
       " ('rem', 75))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.type.freqList(\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('glyph', 470605), ('punct', 29927), ('numr', 463))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.type.freqList(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:18.039544Z",
     "start_time": "2018-05-18T09:18:17.784073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('cons', 1156780),\n",
       " ('empty', 98407),\n",
       " ('missing', 53864),\n",
       " ('sep', 46453),\n",
       " ('punct', 29927),\n",
       " ('unc', 27168),\n",
       " ('term', 15532),\n",
       " ('numr', 2029),\n",
       " ('add', 65),\n",
       " ('foreign', 16))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.type.freqList(\"sign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word matters\n",
    "\n",
    "## Top 20 frequent words\n",
    "\n",
    "We represent words by their essential symbols, collected in the feature *glyph* (which also exists for signs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45393 ו\n",
      "20491 ה\n",
      "19378 ל\n",
      "18225 ב\n",
      " 6389 את\n",
      " 5863 מ\n",
      " 4894 אשר\n",
      " 4789 יהוה\n",
      " 4355 א\n",
      " 4236 כול\n",
      " 4185 על\n",
      " 4172 אל\n",
      " 3262 כי\n",
      " 3091 כ\n",
      " 3005 לא\n",
      " 2841 כל\n",
      " 2424 לוא\n",
      " 1938 ארץ\n",
      " 1829 ישראל\n",
      " 1653 יום\n"
     ]
    }
   ],
   "source": [
    "for (w, amount) in F.glyph.freqList(\"word\")[0:20]:\n",
    "    print(f\"{amount:>5} {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word distribution\n",
    "\n",
    "Let's do a bit more fancy word stuff.\n",
    "\n",
    "### Hapaxes\n",
    "\n",
    "A hapax can be found by picking the words with frequency 1.\n",
    "We do have lexeme information in this corpus, let's use it for determining hapaxes.\n",
    "\n",
    "We print 20 hapaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3813"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes1 = sorted(lx for (lx, amount) in F.lex.freqList(\"word\") if amount == 1)\n",
    "len(hapaxes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #  #  #  #  # \n",
      " #  #  #  #  #  #  #  #  # \n",
      " #  #  #  #  # ות\n",
      " #  #  #  #  # ל #  #  # \n",
      " #  #  #  #  # ם\n",
      " #  #  #  # ב\n",
      " #  #  #  # ה\n",
      " #  #  #  # ו # \n",
      " #  #  #  # ך\n",
      " #  #  #  # ל #  # \n",
      " #  #  #  # תא\n",
      " #  #  # ד\n",
      " #  #  # דב\n",
      " #  #  # דה\n",
      " #  #  # ה #  # \n",
      " #  #  # הו\n",
      " #  #  # הם\n",
      " #  #  # ות\n",
      " #  #  # ט\n",
      " #  #  # כת\n"
     ]
    }
   ],
   "source": [
    "for lx in hapaxes1[0:20]:\n",
    "    print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An other way to find lexemes with only one occurrence is to use the `occ` edge feature from lexeme nodes to the word nodes of\n",
    "its occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3813"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes2 = sorted(F.lex.v(lx) for lx in F.otype.s(\"lex\") if len(E.occ.f(lx)) == 1)\n",
    "len(hapaxes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #  #  #  #  # \n",
      " #  #  #  #  #  #  #  #  # \n",
      " #  #  #  #  # ות\n",
      " #  #  #  #  # ל #  #  # \n",
      " #  #  #  #  # ם\n",
      " #  #  #  # ב\n",
      " #  #  #  # ה\n",
      " #  #  #  # ו # \n",
      " #  #  #  # ך\n",
      " #  #  #  # ל #  # \n",
      " #  #  #  # תא\n",
      " #  #  # ד\n",
      " #  #  # דב\n",
      " #  #  # דה\n",
      " #  #  # ה #  # \n",
      " #  #  # הו\n",
      " #  #  # הם\n",
      " #  #  # ות\n",
      " #  #  # ט\n",
      " #  #  # כת\n"
     ]
    }
   ],
   "source": [
    "for lx in hapaxes2[0:20]:\n",
    "    print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature `lex` contains lexemes that may have uncertain characters in it.\n",
    "\n",
    "The function `glex` has all those characters stripped.\n",
    "Let's use `glex` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3813"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes1g = sorted(lx for (lx, amount) in F.glex.freqList(\"word\") if amount == 1)\n",
    "len(hapaxes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "115\n",
      "126\n",
      "150\n",
      "32\n",
      "350\n",
      "536\n",
      "54\n",
      "61\n",
      "65\n",
      "66\n",
      "67\n",
      "71\n",
      "83\n",
      "92\n",
      "99\n",
      " ידה\n",
      " לוט\n",
      " נַחַל\n",
      " שֵׂעָר\n"
     ]
    }
   ],
   "source": [
    "for lx in hapaxes1g[0:20]:\n",
    "    print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not interested in the numerals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ידה\n",
      " לוט\n",
      " נַחַל\n",
      " שֵׂעָר\n",
      "אֱגֹוז\n",
      "אֱלִידָד\n",
      "אֱלִיעָם\n",
      "אֱלִישֶׁבַע\n",
      "אֲבִיטַל\n",
      "אֲבִיעֶזְרִי\n",
      "אֲבִיעֶזֶר\n",
      "אֲבַטִּיחַ\n",
      "אֲגֹורָה\n",
      "אֲדַמְדַּם\n",
      "אֲדָר\n",
      "אֲדֹנִי\n",
      "אֲדֹנִיָּה\n",
      "אֲדֹרָם\n",
      "אֲהָלִים\n",
      "אֲחִיטוּב\n"
     ]
    }
   ],
   "source": [
    "for lx in [x for x in hapaxes1g if not x.isdigit()][0:20]:\n",
    "    print(lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small occurrence base\n",
    "\n",
    "The occurrence base of a word are the scrolls in which occurs.\n",
    "\n",
    "We compute the occurrence base of each word, based on lexemes according to the `glex` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  8.60s 8264 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase1 = collections.defaultdict(set)\n",
    "\n",
    "A.indent(reset=True)\n",
    "A.info(\"compiling occurrence base ...\")\n",
    "for w in F.otype.s(\"word\"):\n",
    "    scroll = T.sectionFromNode(w)[0]\n",
    "    occurrenceBase1[F.glex.v(w)].add(scroll)\n",
    "A.info(f\"{len(occurrenceBase1)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that took long!\n",
    "\n",
    "We looked up the scroll for each word.\n",
    "\n",
    "But there is another way:\n",
    "\n",
    "Start with scrolls, and iterate through their words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s compiling occurrence base ...\n",
      "  0.58s done\n",
      "  0.58s 8264 entries\n"
     ]
    }
   ],
   "source": [
    "occurrenceBase2 = collections.defaultdict(set)\n",
    "\n",
    "A.indent(reset=True)\n",
    "A.info(\"compiling occurrence base ...\")\n",
    "for s in F.otype.s(\"scroll\"):\n",
    "    scroll = F.scroll.v(s)\n",
    "    for w in L.d(s, otype=\"word\"):\n",
    "        occurrenceBase2[F.glex.v(w)].add(scroll)\n",
    "A.info(\"done\")\n",
    "A.info(f\"{len(occurrenceBase2)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Are the results equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrenceBase1 == occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrenceBase = occurrenceBase2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how many words have how big occurrence bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base size    1 :  2763 words\n",
      "base size    2 :  1123 words\n",
      "base size    3 :   698 words\n",
      "base size    4 :   460 words\n",
      "base size    5 :   336 words\n",
      "base size    6 :   252 words\n",
      "base size    7 :   225 words\n",
      "base size    8 :   182 words\n",
      "base size    9 :   175 words\n",
      "base size   10 :   124 words\n",
      "...\n",
      "base size  459 :     1 words\n",
      "base size  480 :     1 words\n",
      "base size  539 :     1 words\n",
      "base size  600 :     1 words\n",
      "base size  605 :     1 words\n",
      "base size  633 :     1 words\n",
      "base size  745 :     1 words\n",
      "base size  761 :     1 words\n",
      "base size  846 :     1 words\n",
      "base size  987 :     1 words\n"
     ]
    }
   ],
   "source": [
    "occurrenceSize = collections.Counter()\n",
    "\n",
    "for (w, scrolls) in occurrenceBase.items():\n",
    "    occurrenceSize[len(scrolls)] += 1\n",
    "\n",
    "occurrenceSize = sorted(\n",
    "    occurrenceSize.items(),\n",
    "    key=lambda x: (-x[1], x[0]),\n",
    ")\n",
    "\n",
    "for (size, amount) in occurrenceSize[0:10]:\n",
    "    print(f\"base size {size:>4} : {amount:>5} words\")\n",
    "print(\"...\")\n",
    "for (size, amount) in occurrenceSize[-10:]:\n",
    "    print(f\"base size {size:>4} : {amount:>5} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the predicate *private* to those words whose occurrence base is a single scroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2763"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privates = {w for (w, base) in occurrenceBase.items() if len(base) == 1}\n",
    "len(privates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peculiarity of scrolls\n",
    "\n",
    "As a final exercise with scrolls, lets make a list of all scrolls, and show their\n",
    "\n",
    "* total number of words\n",
    "* number of private words\n",
    "* the percentage of private words: a measure of the peculiarity of the scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found    0 empty scrolls\n",
      "Found  517 ordinary scrolls (i.e. without private words)\n"
     ]
    }
   ],
   "source": [
    "scrollList = []\n",
    "\n",
    "empty = set()\n",
    "ordinary = set()\n",
    "\n",
    "for d in F.otype.s(\"scroll\"):\n",
    "    scroll = T.scrollName(d)\n",
    "    words = {F.glex.v(w) for w in L.d(d, otype=\"word\")}\n",
    "    a = len(words)\n",
    "    if not a:\n",
    "        empty.add(scroll)\n",
    "        continue\n",
    "    o = len({w for w in words if w in privates})\n",
    "    if not o:\n",
    "        ordinary.add(scroll)\n",
    "        continue\n",
    "    p = 100 * o / a\n",
    "    scrollList.append((scroll, a, o, p))\n",
    "\n",
    "scrollList = sorted(scrollList, key=lambda e: (-e[3], -e[1], e[0]))\n",
    "\n",
    "print(f\"Found {len(empty):>4} empty scrolls\")\n",
    "print(f\"Found {len(ordinary):>4} ordinary scrolls (i.e. without private words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:52.143337Z",
     "start_time": "2018-05-18T09:18:52.130385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scroll               #all #own %own\n",
      "-----------------------------------\n",
      "4Q341                  32   20 62.5%\n",
      "4Q340                  15    5 33.3%\n",
      "11Q26                   7    2 28.6%\n",
      "4Q124                  86   24 27.9%\n",
      "1Q70bis                12    3 25.0%\n",
      "4Q282d                  8    2 25.0%\n",
      "4Q313a                  4    1 25.0%\n",
      "4Q346a                  4    1 25.0%\n",
      "1Q70                   25    6 24.0%\n",
      "3Q15                  268   57 21.3%\n",
      "4Q561                  74   15 20.3%\n",
      "4Q559                 130   26 20.0%\n",
      "4Q250b                  5    1 20.0%\n",
      "4Q360a                 21    4 19.0%\n",
      "KhQ1                   32    6 18.8%\n",
      "4Q347                  11    2 18.2%\n",
      "4Q575a                 12    2 16.7%\n",
      "1Q58                    6    1 16.7%\n",
      "4Q468bb                 6    1 16.7%\n",
      "11Q10                 635  102 16.1%\n",
      "...\n",
      "4Q367                 173    1  0.6%\n",
      "4Q2                   174    1  0.6%\n",
      "4Q366                 186    1  0.5%\n",
      "4Q98                  192    1  0.5%\n",
      "4Q56                  963    5  0.5%\n",
      "4Q394                 194    1  0.5%\n",
      "4Q59                  404    2  0.5%\n",
      "4Q88                  208    1  0.5%\n",
      "11Q20                 429    2  0.5%\n",
      "4Q57                  875    4  0.5%\n",
      "11Q11                 222    1  0.5%\n",
      "4Q58                  451    2  0.4%\n",
      "4Q174                 241    1  0.4%\n",
      "4Q13                  257    1  0.4%\n",
      "4Q524                 280    1  0.4%\n",
      "4Q271                 294    1  0.3%\n",
      "4Q84                  350    1  0.3%\n",
      "4Q33                  365    1  0.3%\n",
      "4Q428                 385    1  0.3%\n",
      "1QpHab                463    1  0.2%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"{:<20}{:>5}{:>5}{:>5}\\n{}\".format(\n",
    "        \"scroll\",\n",
    "        \"#all\",\n",
    "        \"#own\",\n",
    "        \"%own\",\n",
    "        \"-\" * 35,\n",
    "    )\n",
    ")\n",
    "\n",
    "for x in scrollList[0:20]:\n",
    "    print(\"{:<20} {:>4} {:>4} {:>4.1f}%\".format(*x))\n",
    "print(\"...\")\n",
    "for x in scrollList[-20:]:\n",
    "    print(\"{:<20} {:>4} {:>4} {:>4.1f}%\".format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip\n",
    "\n",
    "See the [lexeme recipe](cookbook/lexeme.ipynb) in the cookbook for how you get from a lexeme node to\n",
    "its word occurrence nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality API\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow or precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first word to the scroll it contains.\n",
    "Note the `[0]` at the end. You expect one scroll, yet `L` returns a tuple.\n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:55.410034Z",
     "start_time": "2018-05-18T09:18:55.404051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605868\n"
     ]
    }
   ],
   "source": [
    "firstScroll = L.u(1, otype=\"scroll\")[0]\n",
    "print(firstScroll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of sign 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:56.772513Z",
     "start_time": "2018-05-18T09:18:56.766324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign 3 is contained in scroll 1605868\n",
      "sign 3 is contained in lex 1542524\n",
      "sign 3 is contained in fragment 1531341\n",
      "sign 3 is contained in line 1552973\n",
      "sign 3 is contained in cluster x\n",
      "sign 3 is contained in word 1606870\n"
     ]
    }
   ],
   "source": [
    "s = 3\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType:\n",
    "        continue\n",
    "    up = L.u(s, otype=otype)\n",
    "    upNode = \"x\" if len(up) == 0 else up[0]\n",
    "    print(\"sign {} is contained in {} {}\".format(s, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first scroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:18:58.821681Z",
     "start_time": "2018-05-18T09:18:58.814893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17149: sign          first slot=17149 , last slot=17149 \n",
      "1612982: word          first slot=17149 , last slot=17149 \n",
      "1553387: line          first slot=17149 , last slot=17176 \n",
      "1531359: fragment      first slot=17149 , last slot=18207 \n",
      "1605869: scroll        first slot=17149 , last slot=33885 \n"
     ]
    }
   ],
   "source": [
    "afterFirstScroll = L.n(firstScroll)\n",
    "for n in afterFirstScroll:\n",
    "    print(\n",
    "        \"{:>7}: {:<13} first slot={:<6}, last slot={:<6}\".format(\n",
    "            n,\n",
    "            F.otype.v(n),\n",
    "            E.oslots.s(n)[0],\n",
    "            E.oslots.s(n)[-1],\n",
    "        )\n",
    "    )\n",
    "secondScroll = L.n(firstScroll, otype=\"scroll\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second scroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:00.163973Z",
     "start_time": "2018-05-18T09:19:00.154857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605868: scroll        first slot=1     , last slot=17148 \n",
      "1531358: fragment      first slot=15658 , last slot=17148 \n",
      "1553386: line          first slot=17099 , last slot=17148 \n",
      "1612981: word          first slot=17147 , last slot=17148 \n",
      "  17148: sign          first slot=17148 , last slot=17148 \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondScroll):\n",
    "    print(\n",
    "        \"{:>7}: {:<13} first slot={:<6}, last slot={:<6}\".format(\n",
    "            n,\n",
    "            F.otype.v(n),\n",
    "            E.oslots.s(n)[0],\n",
    "            E.oslots.s(n)[-1],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the fragments of the first scroll, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:02.530705Z",
     "start_time": "2018-05-18T09:19:02.475279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "fragments = L.d(firstScroll, otype=\"fragment\")\n",
    "print(len(fragments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first line\n",
    "We pick two nodes and explore what is above and below them:\n",
    "the first line and the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:04.024679Z",
     "start_time": "2018-05-18T09:19:03.995207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1606869\n",
      "   |   UP\n",
      "   |      |   1542523         lex\n",
      "   |      |   1552973         line\n",
      "   |      |   1531341         fragment\n",
      "   |      |   1605868         scroll\n",
      "   |   DOWN\n",
      "   |      |   2               sign\n",
      "Node 1552973\n",
      "   |   UP\n",
      "   |      |   1531341         fragment\n",
      "   |      |   1605868         scroll\n",
      "   |   DOWN\n",
      "   |      |   1430242         cluster\n",
      "   |      |   1               sign\n",
      "   |      |   1606869         word\n",
      "   |      |   2               sign\n",
      "   |      |   1606870         word\n",
      "   |      |   3               sign\n",
      "   |      |   4               sign\n",
      "   |      |   5               sign\n",
      "   |      |   1606871         word\n",
      "   |      |   6               sign\n",
      "   |      |   7               sign\n",
      "   |      |   8               sign\n",
      "   |      |   9               sign\n",
      "   |      |   1606872         word\n",
      "   |      |   10              sign\n",
      "   |      |   11              sign\n",
      "   |      |   1606873         word\n",
      "   |      |   12              sign\n",
      "   |      |   13              sign\n",
      "   |      |   14              sign\n",
      "   |      |   15              sign\n",
      "   |      |   16              sign\n",
      "   |      |   1606874         word\n",
      "   |      |   17              sign\n",
      "   |      |   18              sign\n",
      "   |      |   19              sign\n",
      "   |      |   1606875         word\n",
      "   |      |   20              sign\n",
      "   |      |   1606876         word\n",
      "   |      |   21              sign\n",
      "   |      |   22              sign\n",
      "   |      |   23              sign\n",
      "   |      |   24              sign\n",
      "   |      |   1606877         word\n",
      "   |      |   25              sign\n",
      "   |      |   1606878         word\n",
      "   |      |   26              sign\n",
      "   |      |   27              sign\n",
      "   |      |   28              sign\n",
      "   |      |   29              sign\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for n in [\n",
    "    F.otype.s(\"word\")[0],\n",
    "    F.otype.s(\"line\")[0],\n",
    "]:\n",
    "    A.indent(level=0)\n",
    "    A.info(\"Node {}\".format(n), tm=False)\n",
    "    A.indent(level=1)\n",
    "    A.info(\"UP\", tm=False)\n",
    "    A.indent(level=2)\n",
    "    A.info(\"\\n\".join([\"{:<15} {}\".format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    A.indent(level=1)\n",
    "    A.info(\"DOWN\", tm=False)\n",
    "    A.indent(level=2)\n",
    "    A.info(\"\\n\".join([\"{:<15} {}\".format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "A.indent(level=0)\n",
    "A.info(\"Done\", tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "So far, we have mainly seen nodes and their numbers, and the names of node types.\n",
    "You would almost forget that we are dealing with text.\n",
    "So let's try to see some text.\n",
    "\n",
    "In the same way as `F` gives access to feature data,\n",
    "`T` gives access to the text.\n",
    "That is also feature data, but you can tell Text-Fabric which features are specifically\n",
    "carrying the text, and in return Text-Fabric offers you\n",
    "a Text API: `T`.\n",
    "\n",
    "## Formats\n",
    "DSS text can be represented in a number of ways:\n",
    "\n",
    "* `orig`: unicode\n",
    "* `trans`: ETCBC transcription\n",
    "* `source`: as in Abegg's data files\n",
    "\n",
    "All three can be represented in two flavours:\n",
    "\n",
    "* `full`: all glyphs, but no bracketings and flags\n",
    "* `extra`: everything\n",
    "\n",
    "If you wonder where the information about text formats is stored:\n",
    "not in the program text-fabric, but in the data set.\n",
    "It has a feature `otext`, which specifies the formats and which features\n",
    "must be used to produce them. `otext` is the third special feature in a TF data set,\n",
    "next to `otype` and `oslots`.\n",
    "It is an optional feature.\n",
    "If it is absent, there will be no `T` API.\n",
    "\n",
    "Here is a list of all available formats in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lex-default': 'word',\n",
       " 'lex-orig-full': 'word',\n",
       " 'lex-source-full': 'word',\n",
       " 'lex-trans-full': 'word',\n",
       " 'morph-source-full': 'word',\n",
       " 'text-orig-extra': 'word',\n",
       " 'text-orig-full': 'sign',\n",
       " 'text-source-extra': 'word',\n",
       " 'text-source-full': 'sign',\n",
       " 'text-trans-extra': 'word',\n",
       " 'text-trans-full': 'sign',\n",
       " 'layout-orig-full': 'sign',\n",
       " 'layout-source-full': 'sign',\n",
       " 'layout-trans-full': 'sign'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "\n",
    "The ` T.text()` function is central to get text representations of nodes. Its most basic usage is\n",
    "\n",
    "```python\n",
    "T.text(nodes, fmt=fmt)\n",
    "```\n",
    "where `nodes` is a list or iterable of nodes, usually word nodes, and `fmt` is the name of a format.\n",
    "If you leave out `fmt`, the default `text-orig-full` is chosen.\n",
    "\n",
    "The result is the text in that format for all nodes specified:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see for each format in the list above its intended level of operation: `sign` or `word`.\n",
    "\n",
    "If TF formats a node according to a defined text-format, it will descend to constituent nodes and represent those\n",
    "constituent nodes.\n",
    "\n",
    "In this case, the formats ending in `-extra` specify the `word` level as the descend type.\n",
    "Because, in this dataset, the features that contain the text-critical brackets are only defined at the word level.\n",
    "At the sign level, those brackets are no longer visible, but they have left their traces in other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the **default** format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine a portion of biblical material at the start 1Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540222"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragmentNode = T.nodeFromSection((\"1Q1\", \"f1\"))\n",
    "fragmentNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fragment ('1Q1', 'f1') with\n",
      "  157 signs\n",
      "   57 words\n",
      "    3 lines\n",
      "\n"
     ]
    }
   ],
   "source": [
    "signs = L.d(fragmentNode, otype=\"sign\")\n",
    "words = L.d(fragmentNode, otype=\"word\")\n",
    "lines = L.d(fragmentNode, otype=\"line\")\n",
    "print(\n",
    "    f\"\"\"\n",
    "Fragment {T.sectionFromNode(fragmentNode)} with\n",
    "  {len(signs):>3} signs\n",
    "  {len(words):>3} words\n",
    "  {len(lines):>3} lines\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וירא אלהים כי טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ╱ אלהים ישרוצו המים שרץ נפש חיה ועוף יעופף על הארץ על פני רקיע השמים '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(signs[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וירא אלהים כי טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר אלהים ישרוצו ה'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:13.490426Z",
     "start_time": "2018-05-18T09:19:13.486053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'וירא אלהים כי טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ╱ אלהים ישרוצו המים שרץ נפש חיה ועוף יעופף על הארץ על פני רקיע השמים ׃ ╱ '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(lines[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `-extra` formats\n",
    "\n",
    "In order to use non-default formats, we have to specify them in the *fmt* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(signs[0:100], fmt=\"text-orig-extra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not get much, let's ask why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPLANATION: T.text() called with parameters:\n",
      "\tnodes  : iterable of 2 nodes\n",
      "\tfmt    : text-orig-extra targeted at word\n",
      "\tdescend: implicit\n",
      "\tfunc   : no custom format implementation\n",
      "\n",
      "\tNODE: sign 770999\n",
      "\t\tTARGET LEVEL: word  (descend=None) (format target type)\n",
      "\t\tEXPANSION: 0 words \n",
      "\t\tFORMATTING: explicit text-orig-extra does <function Text._compileFormat.<locals>.g at 0x7fdcc92d2050>\n",
      "\t\tMATERIAL:\n",
      "\tNODE: sign 771000\n",
      "\t\tTARGET LEVEL: word  (descend=None) (format target type)\n",
      "\t\tEXPANSION: 0 words \n",
      "\t\tFORMATTING: explicit text-orig-extra does <function Text._compileFormat.<locals>.g at 0x7fdcc92d2050>\n",
      "\t\tMATERIAL:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(signs[0:2], fmt=\"text-orig-extra\", explain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason can be found in `TARGET LEVEL: word` and `EXPANSION 0 words`.\n",
    "We are applying the word targeted format `text-orig-extra` to a sign, which does not contain words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ וירא אל ]הים כי [ טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ] [ אלהים יש ]רוצו ה'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:20], fmt=\"text-orig-extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ וירא אל ]הים כי [ טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ] [ אלהים יש ]רוצו המים שר#[ ץ נפש חיה ועוף יעופף על הארץ על פני רקיע השמים ׃ '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(lines[0:2], fmt=\"text-orig-extra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the direction of the brackets look wrong, because they have not been adapted to the right-to-left writing direction.\n",
    "\n",
    "We can view them in ETCBC transcription as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ WJR> >L ]HJm KJ [ VWB 00 WJHJ <RB WJHJ BQR JWm RBJ<J 00 WJ>MR ] [ >LHJm J# ]RWYW H'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:20], fmt=\"text-trans-extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ WJR> >L ]HJm KJ [ VWB 00 WJHJ <RB WJHJ BQR JWm RBJ<J 00 WJ>MR ] [ >LHJm J# ]RWYW HMJm #R#[ y NP# XJH W<Wp J<WPp <L H>Ry <L PNJ RQJ< H#MJm 00 '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(lines[0:2], fmt=\"text-trans-extra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in Abegg's source encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "']wyra al[hyM ky ]fwb . wyhy orb wyhy bqr ywM rbyoy . wyamr[ ]alhyM yC[rwxw h'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(words[0:20], fmt=\"text-source-extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "']wyra al[hyM ky ]fwb . wyhy orb wyhy bqr ywM rbyoy . wyamr[ ]alhyM yC[rwxw hmyM Cr«]X npC jyh wowP yowpP ol harX ol pny rqyo hCmyM . '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(lines[0:2], fmt=\"text-source-extra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `T.text()` works with nodes of many types.\n",
    "\n",
    "We compose a set of example nodes and run `T.text` on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1606870, 1430242, 1552973, 1531341, 1605868, 1542524]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleNodes = [\n",
    "    F.otype.s(\"sign\")[1],\n",
    "    F.otype.s(\"word\")[1],\n",
    "    F.otype.s(\"cluster\")[0],\n",
    "    F.otype.s(\"line\")[0],\n",
    "    F.otype.s(\"fragment\")[0],\n",
    "    F.otype.s(\"scroll\")[0],\n",
    "    F.otype.s(\"lex\")[1],\n",
    "]\n",
    "exampleNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is sign 2:\n",
      "ו\n",
      "\n",
      "This is word 1606870:\n",
      "עתה \n",
      "\n",
      "This is cluster 1430242:\n",
      "  \n",
      "\n",
      "This is line 1552973:\n",
      "  ועתה שמעו כל יודעי צדק ובינו במעשי \n",
      "\n",
      "This is fragment 1531341:\n",
      "  ועתה שמעו כל יודעי צדק ובינו במעשי אל ׃ כי ריב ל׳ו עם כל בשר ומשפט יעשה בכל מנאצי׳ו ׃ כי במועל׳ם אשר עזבו׳הו הסתיר פני׳ו מישראל וממקדש׳ו ויתנ׳ם לחרב ׃ ובזכר׳ו ברית ראשנים השאיר שאירית לישראל ולא נתנ\n",
      "and 827 characters more\n",
      "\n",
      "This is scroll 1605868:\n",
      "  ועתה שמעו כל יודעי צדק ובינו במעשי אל ׃ כי ריב ל׳ו עם כל בשר ומשפט יעשה בכל מנאצי׳ו ׃ כי במועל׳ם אשר עזבו׳הו הסתיר פני׳ו מישראל וממקדש׳ו ויתנ׳ם לחרב ׃ ובזכר׳ו ברית ראשנים השאיר שאירית לישראל ולא נתנ\n",
      "and 21145 characters more\n",
      "\n",
      "This is lex 1542524:\n",
      "h-עַתָּה-<AT.@H-oAt;Dh \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in exampleNodes:\n",
    "    print(f\"This is {F.otype.v(n)} {n}:\")\n",
    "    text = T.text(n)\n",
    "    if len(text) > 200:\n",
    "        text = text[0:200] + f\"\\nand {len(text) - 200} characters more\"\n",
    "    print(text)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the last case, the lexeme node: obviously, the text-format that has been invoked provides\n",
    "the *language* (`h`) of the lexeme, plus its representations in unicode, etcbc, and Abegg transcription.\n",
    "\n",
    "But what format exactly has been invoked?\n",
    "Let's ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPLANATION: T.text() called with parameters:\n",
      "\tnodes  : single node\n",
      "\tfmt    : implicit\n",
      "\tdescend: implicit\n",
      "\tfunc   : no custom format implementation\n",
      "\n",
      "\tNODE: lex 1542524\n",
      "\t\tTARGET LEVEL: lex (no expansion needed) (descend=None) (format target type)\n",
      "\t\tEXPANSION: 1 lex 1542524\n",
      "\t\tFORMATTING: implicit lex-default does <function Text._compileFormat.<locals>.g at 0x7fdcc92237a0>\n",
      "\t\tMATERIAL:\n",
      "\t\t\tlex 1542524 ADDS \"h-עַתָּה-<AT.@H-oAt;Dh \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'h-עַתָּה-<AT.@H-oAt;Dh '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(exampleNodes[-1], explain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clue is in `FORMATTING: implicit lex-default`.\n",
    "\n",
    "Remember that we saw the format `lex-default` in `T.formats`.\n",
    "\n",
    "The Text-API has matched the type of the lexeme node we provided with this default format and applies it,\n",
    "thereby skipping the expansion of the lexeme node to its occurrences.\n",
    "\n",
    "But we can force the expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh h-עַתָּה-<AT.@H-oAt;Dh '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.text(exampleNodes[-1], fmt=\"lex-default\", descend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "Now let's use those formats to print out the first biblical line in this corpus.\n",
    "\n",
    "Note that the formats starting with `layout-` are not usable for this.\n",
    "Also the format `lex-default` is not useful, so we leave that out as well.\n",
    "\n",
    "For the `layout-` formats, see [display](display.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefulFormats = [\n",
    "    fmt\n",
    "    for fmt in sorted(T.formats)\n",
    "    if not fmt.startswith(\"layout-\") and not fmt == \"lex-default\"\n",
    "]\n",
    "len(usefulFormats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:10.077589Z",
     "start_time": "2018-05-18T09:19:10.070503Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex-orig-full:\n",
      "\th-וְh-ראה h-אֱלֹהִים h-כִּי h-טֹוב h-׃ h-וְh-היה h-עֶרֶב h-וְh-היה h-בֹּקֶר h-יֹום h-רְבִיעִי h-׃ h-וְh-אמר \n",
      "\n",
      "lex-source-full:\n",
      "\th-w◊h-rah h-aTløhIyM h-k;Iy h-føwb h-. h-w◊h-hyh h-oRr®b h-w◊h-hyh h-b;Oq®r h-yøwM h-r√bIyoIy h-. h-w◊h-amr \n",
      "\n",
      "lex-trans-full:\n",
      "\th-W:h-R>H h->:ELOHIJm h-K.IJ h-VOWB h-00 h-W:h-HJH h-<EREB h-W:h-HJH h-B.OQER h-JOWm h-R:BIJ<IJ h-00 h-W:h->MR \n",
      "\n",
      "morph-source-full:\n",
      "\tPcvqw3msj ncmp Pc ams . Pcvqw3msj ncms Pcvqw3msj ncms ncms uomsa . Pcvqw3ms \n",
      "\n",
      "text-orig-extra:\n",
      "\t[ וירא אל ]הים כי [ טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ] \n",
      "\n",
      "text-orig-full:\n",
      "\tוירא אלהים כי טוב ׃ ויהי ערב ויהי בקר יום רביעי ׃ ויאמר ╱ \n",
      "\n",
      "text-source-extra:\n",
      "\t]wyra al[hyM ky ]fwb . wyhy orb wyhy bqr ywM rbyoy . wyamr[ \n",
      "\n",
      "text-source-full:\n",
      "\twyra alhyM ky fwb . wyhy orb wyhy bqr ywM rbyoy . wyamr ╱ \n",
      "\n",
      "text-trans-extra:\n",
      "\t[ WJR> >L ]HJm KJ [ VWB 00 WJHJ <RB WJHJ BQR JWm RBJ<J 00 WJ>MR ] \n",
      "\n",
      "text-trans-full:\n",
      "\tWJR> >LHJm KJ VWB 00 WJHJ <RB WJHJ BQR JWm RBJ<J 00 WJ>MR ╱ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstLine = T.nodeFromSection((\"1Q1\", \"f1\", \"1\"))\n",
    "for fmt in usefulFormats:\n",
    "    if not fmt.startswith(\"layout-\"):\n",
    "        print(\n",
    "            \"{}:\\n\\t{}\\n\".format(\n",
    "                fmt,\n",
    "                T.text(firstLine, fmt=fmt),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in a few seconds\n",
    "Part of the pleasure of working with computers is that they can crunch massive amounts of data.\n",
    "The text of the Dead Sea Scrolls is a piece of cake.\n",
    "\n",
    "It takes just a dozen seconds or so to have that cake and eat it.\n",
    "In all useful formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:27.839331Z",
     "start_time": "2018-05-18T09:19:18.526400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s writing plain text of all scrolls in all text formats\n",
      "    11s done 6 formats\n",
      "text-orig-extra\n",
      "ועתה שמעו כל יודעי צדק ובינו במעשי \n",
      "אל ׃ כי ריב ל׳ו עם כל בשר ומשפט יעשה בכל מנאצי׳ו ׃ \n",
      "כי במועל׳ם אשר עזבו׳הו הסתיר פני׳ו מישראל וממקדש׳ו \n",
      "ו?יתנ׳ם לחרב ׃ ובזכר׳ו ברית ראשנים השאיר שאירית \n",
      "לישראל ולא נתנ׳ם לכלה ׃ ובקץ חרון שנים שלוש מאות \n",
      "\n",
      "text-orig-full\n",
      "  ועתה שמעו כל יודעי צדק ובינו במעשי \n",
      "אל ׃ כי ריב ל׳ו עם כל בשר ומשפט יעשה בכל מנאצי׳ו ׃ \n",
      "כי במועל׳ם אשר עזבו׳הו הסתיר פני׳ו מישראל וממקדש׳ו \n",
      "ויתנ׳ם לחרב ׃ ובזכר׳ו ברית ראשנים השאיר שאירית \n",
      "לישראל ולא נתנ׳ם לכלה ׃ ובקץ חרון שנים שלוש מאות \n",
      "\n",
      "text-source-extra\n",
      "woth Cmow kl ywdoy xdq wbynw bmoCy \n",
      "al . ky ryb l/w oM kl bCr wmCpf yoCh bkl mnaxy/w . \n",
      "ky bmwol/M aCr ozbw/hw hstyr pny/w myCral wmmqdC/w \n",
      "wØytn/M ljrb . wbzkr/w bryt raCnyM hCayr Cayryt \n",
      "lyCral wla ntn/M lklh . wbqX jrwN CnyM ClwC mawt \n",
      "\n",
      "text-source-full\n",
      "□ woth Cmow kl ywdoy xdq wbynw bmoCy \n",
      "al . ky ryb l/w oM kl bCr wmCpf yoCh bkl mnaxy/w . \n",
      "ky bmwol/M aCr ozbw/hw hstyr pny/w myCral wmmqdC/w \n",
      "wytn/M ljrb . wbzkr/w bryt raCnyM hCayr Cayryt \n",
      "lyCral wla ntn/M lklh . wbqX jrwN CnyM ClwC mawt \n",
      "\n",
      "text-trans-extra\n",
      "W<TH #M<W KL JWD<J YDQ WBJNW BM<#J \n",
      ">L 00 KJ RJB L'W <m KL B#R WM#PV J<#H BKL MN>YJ'W 00 \n",
      "KJ BMW<L'm >#R <ZBW'HW HSTJR PNJ'W MJ#R>L WMMQD#'W \n",
      "W?JTN'm LXRB 00 WBZKR'W BRJT R>#NJm H#>JR #>JRJT \n",
      "LJ#R>L WL> NTN'm LKLH 00 WBQy XRWn #NJm #LW# M>WT \n",
      "\n",
      "text-trans-full\n",
      "  W<TH #M<W KL JWD<J YDQ WBJNW BM<#J \n",
      ">L 00 KJ RJB L'W <m KL B#R WM#PV J<#H BKL MN>YJ'W 00 \n",
      "KJ BMW<L'm >#R <ZBW'HW HSTJR PNJ'W MJ#R>L WMMQD#'W \n",
      "WJTN'm LXRB 00 WBZKR'W BRJT R>#NJm H#>JR #>JRJT \n",
      "LJ#R>L WL> NTN'm LKLH 00 WBQy XRWn #NJm #LW# M>WT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "A.indent(reset=True)\n",
    "A.info(\"writing plain text of all scrolls in all text formats\")\n",
    "\n",
    "text = collections.defaultdict(list)\n",
    "\n",
    "for ln in F.otype.s(\"line\"):\n",
    "    for fmt in usefulFormats:\n",
    "        if fmt.startswith(\"text-\"):\n",
    "            text[fmt].append(T.text(ln, fmt=fmt, descend=True))\n",
    "\n",
    "A.info(\"done {} formats\".format(len(text)))\n",
    "\n",
    "for fmt in sorted(text):\n",
    "    print(\"{}\\n{}\\n\".format(fmt, \"\\n\".join(text[fmt][0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full plain text\n",
    "We write all formats to file, in your `Downloads` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:34.250294Z",
     "start_time": "2018-05-18T09:19:34.156658Z"
    }
   },
   "outputs": [],
   "source": [
    "for fmt in T.formats:\n",
    "    if fmt.startswith(\"text-\"):\n",
    "        with open(\n",
    "            os.path.expanduser(f\"~/Downloads/{fmt}.txt\"),\n",
    "            \"w\",\n",
    "            # encoding='utf8',\n",
    "        ) as f:\n",
    "            f.write(\"\\n\".join(text[fmt]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(if this errors, uncomment the line with `encoding`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "\n",
    "A section in the DSS is a scroll, a fragment or a line.\n",
    "Knowledge of sections is not baked into Text-Fabric.\n",
    "The config feature `otext.tf` may specify three section levels, and tell\n",
    "what the corresponding node types and features are.\n",
    "\n",
    "From that knowledge it can construct mappings from nodes to sections, e.g. from line\n",
    "nodes to tuples of the form:\n",
    "\n",
    "    (scroll acronym, fragment label, line number)\n",
    "\n",
    "You can get the section of a node as a tuple of relevant scroll, fragment, and line nodes.\n",
    "Or you can get it as a passage label, a string.\n",
    "\n",
    "You can ask for the passage corresponding to the first slot of a node, or the one corresponding to the last slot.\n",
    "\n",
    "If you are dealing with scroll and fragment nodes, you can ask to fill out the line and fragment parts as well.\n",
    "\n",
    "Here are examples of getting the section that corresponds to a node and vice versa.\n",
    "\n",
    "**NB:** `sectionFromNode` always delivers a line specification, either from the\n",
    "first slot belonging to that node, or, if `lastSlot`, from the last slot\n",
    "belonging to that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "someNodes = (\n",
    "    F.otype.s(\"sign\")[100000],\n",
    "    F.otype.s(\"word\")[10000],\n",
    "    F.otype.s(\"cluster\")[5000],\n",
    "    F.otype.s(\"line\")[15000],\n",
    "    F.otype.s(\"fragment\")[1000],\n",
    "    F.otype.s(\"scroll\")[500],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T09:19:43.056511Z",
     "start_time": "2018-05-18T09:19:43.043552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100001 sign     - 1QHa 25:31         1QHa 25:31         ((1605874, 1531445, 1555227), (1605874, 1531445, 1555227))\n",
      "1616869 word     - 1QS 8:10           1QS 8:10           ((1605869, 1531366, 1553578), (1605869, 1531366, 1553578))\n",
      "1435242 cluster  - 1Q29 f2:3          1Q29 f2:3          ((1605890, 1531685, 1556400), (1605890, 1531685, 1556400))\n",
      "1567973 line     - 4Q368 f3:4         4Q368 f3:4         ((1606221, 1534207, 1567973), (1606221, 1534207, 1567973))\n",
      "1532341 fragment - 4Q186 f2ii         4Q186 f2ii:3       ((1605991, 1532341), (1605991, 1532341, 1559220))\n",
      "1606368 scroll   - 4Q471b             4Q471b f1a_d:10    ((1606368,), (1606368, 1536089, 1575660))\n"
     ]
    }
   ],
   "source": [
    "for n in someNodes:\n",
    "    nType = F.otype.v(n)\n",
    "    d = f\"{n:>7} {nType}\"\n",
    "    first = A.sectionStrFromNode(n)\n",
    "    last = A.sectionStrFromNode(n, lastSlot=True, fillup=True)\n",
    "    tup = (\n",
    "        T.sectionTuple(n),\n",
    "        T.sectionTuple(n, lastSlot=True, fillup=True),\n",
    "    )\n",
    "    print(f\"{d:<16} - {first:<18} {last:<18} {tup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the corpus.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "* **[display](display.ipynb)** become an expert in creating pretty displays of your text structures\n",
    "* **[search](search.ipynb)** turbo charge your hand-coding with search templates\n",
    "* **[exportExcel](exportExcel.ipynb)** make tailor-made spreadsheets out of your results\n",
    "* **[share](share.ipynb)** draw in other people's data and let them use yours\n",
    "* **[similarLines](similarLines.ipynb)** spot the similarities between lines\n",
    "\n",
    "---\n",
    "\n",
    "See the [cookbook](cookbook) for recipes for small, concrete tasks.\n",
    "\n",
    "CC-BY Dirk Roorda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
